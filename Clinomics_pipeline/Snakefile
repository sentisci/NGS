#Load python modules
import itertools
import os
import collections
import pprint
from snakemake.utils import R
from snakemake.exceptions import MissingInputException

# Environment variable for serpentine base directory location
try:
    SERPENTINE_HOME=os.environ['SERPENTINE_HOME']
except KeyError:
    SERPENTINE_HOME="/projects/Clinomics/Tools/serpentine_Tgen/"
    pass

#Basic utility functions
def _get_rule_path(rule_file_path):
    "Combines the serpentine base directory with serpentine rule paths"
    return(os.path.join(SERPENTINE_HOME,rule_file_path))

#Include all config files
configfile: _get_rule_path("cluster.json")
configfile: _get_rule_path("config.json")
configfile: _get_rule_path("version.json")
configfile: _get_rule_path("samplesheet.json")

#Include all rule files
include: _get_rule_path("alignment.rules")

#Store Entity in Dicts
#START####Basic dicts###################################################
UNIT_TO_LIBRARY = {}
for lib,units in config['libraries'].items():
	for unit in units:
	        UNIT_TO_LIBRARY[unit]=lib

LIBRARY_TO_SAMPLE  = {}
for sample,libs in config['samples'].items():
	for lib in libs:
        	LIBRARY_TO_SAMPLE[lib]=sample

SAMPLE_TO_SUBJECT  = {}
for subject,samples in config['subjects'].items():
	for sample in samples:
        	SAMPLE_TO_SUBJECT[sample]=subject

SUBJECT_TO_STUDY  = {}
for study,subjects in config['studies'].items():
	for subject in subjects:
		SUBJECT_TO_STUDY[subject]=study

#END################################################################

#START## Forward one step #########################################
UNIT_TO_SAMPLE = {}
for unit in config['units'].keys():
	UNIT_TO_SAMPLE[unit]=LIBRARY_TO_SAMPLE[UNIT_TO_LIBRARY[unit]]

UNIT_TO_SUBJECT = {}
for unit in config['units'].keys():
    	UNIT_TO_SUBJECT[unit]=SAMPLE_TO_SUBJECT[LIBRARY_TO_SAMPLE[UNIT_TO_LIBRARY[unit]]]

UNIT_TO_STUDY = {}
for unit in config['units'].keys():
    	UNIT_TO_STUDY[unit]=SUBJECT_TO_STUDY[SAMPLE_TO_SUBJECT[LIBRARY_TO_SAMPLE[UNIT_TO_LIBRARY[unit]]]]
#END# ############################################################


#START## BAckward one step ######################################
LIBRARY_TO_UNIT = collections.defaultdict(list)
for unit,sample in UNIT_TO_LIBRARY.items():
        LIBRARY_TO_UNIT[sample].append(unit)

SAMPLE_TO_UNIT = collections.defaultdict(list)
for unit,sample in UNIT_TO_SAMPLE.items():
    	SAMPLE_TO_UNIT[sample].append(unit)

SUBJECT_TO_UNIT = collections.defaultdict(list)
for unit,subject in UNIT_TO_SUBJECT.items():
    	SUBJECT_TO_UNIT[subject].append(unit)

STUDY_TO_UNIT = collections.defaultdict(list)
for unit,study in UNIT_TO_STUDY.items():
    	STUDY_TO_UNIT[study].append(unit)

#END ##########################################################
## bam files
BAMS = ["SUBJECT/{subject}/{sample}/{reference_name}.{aligner}/bam/{sample}.final.bam".format(subject=SAMPLE_TO_SUBJECT[s], sample=s, reference_name=config['reference_name'], aligner=config['aligner']) for s in config['samples'].keys() ]
BAMS_tdf = ["SUBJECT/{subject}/{sample}/{reference_name}.{aligner}/bam/{sample}.final.tdf".format(subject=SAMPLE_TO_SUBJECT[s], sample=s, reference_name=config['reference_name'], aligner=config['aligner']) for s in config['samples'].keys() ] 
BAM_readDepth= ["SUBJECT/{subject}/{sample}/{reference_name}.{aligner}/qc/{sample}.final.bam.depth".format(subject=SAMPLE_TO_SUBJECT[s], sample=s, reference_name=config['reference_name'], aligner=config['aligner']) for s in config['samples'].keys() ]
BAM_hsmetrics= ["SUBJECT/{subject}/{sample}/{reference_name}.{aligner}/qc/{sample}.final.bam.hsmetrics".format(subject=SAMPLE_TO_SUBJECT[s], sample=s, reference_name=config['reference_name'], aligner=config['aligner']) for s in config['samples'].keys() ]
BAM_hotspotCov= ["SUBJECT/{subject}/{sample}/{reference_name}.{aligner}/qc/{sample}.final.bam.hotspot.depth".format(subject=SAMPLE_TO_SUBJECT[s], sample=s, reference_name=config['reference_name'], aligner=config['aligner']) for s in config['samples'].keys() ]
BAMS_flagstat	= ["SUBJECT/{subject}/{sample}/{reference_name}.{aligner}/qc/{sample}.final.bam.flagstat".format(subject=SAMPLE_TO_SUBJECT[s], sample=s, reference_name=config['reference_name'], aligner=config['aligner']) for s in config['samples'].keys()]
BAMS_bamqc	= ["SUBJECT/{subject}/{sample}/{reference_name}.{aligner}/qc/bamqc/{sample}.final.bam.qualimapReport.html".format(subject=SAMPLE_TO_SUBJECT[s], sample=s, reference_name=config['reference_name'], aligner=config['aligner']) for s in config['samples'].keys()]
ALL_FASTQC  	= ["SUBJECT/{subject}/{sample}/{reference_name}.{aligner}/qc/fastqc/{unit}_R1_fastqc.html".format(sample=UNIT_TO_SAMPLE[s], subject=UNIT_TO_SUBJECT[s], unit=s, reference_name=config['reference_name'], aligner=config['aligner']) for s in config['units'].keys()]

All_QC = BAMS_tdf + BAM_readDepth + BAM_hsmetrics + BAM_hotspotCov + BAMS_flagstat + BAMS_bamqc + ALL_FASTQC

somaticPairs = {}
PairsCapture = {}

if len(config['sample_references']) > 0:
	for Tumor in config['sample_references']:
		for Normal in config['sample_references'][Tumor]:
			TumorBam="SUBJECT/{subject}/{sample}/{reference_name}.{aligner}/bam/{sample}.final".format(subject=SAMPLE_TO_SUBJECT[Tumor], sample=Tumor, reference_name=config['reference_name'],aligner=config["aligner"])
#			#TumorBam  = "{sample}.final".format(sample=Tumor)
			NormalBam =  "SUBJECT/{subject}/{sample}/{reference_name}.{aligner}/bam/{sample}.final".format(subject=SAMPLE_TO_SUBJECT[Normal], sample=Normal, reference_name=config['reference_name'],aligner=config["aligner"])
#			#NormalBam = "{sample}.final".format(sample=Normal)
			PairsCapture[Tumor] = config['sample_captures'][Tumor]
			somaticPairs[Tumor] = [NormalBam + ".bam" , NormalBam + ".bai", TumorBam + ".bam", TumorBam + ".bai"]

#print(PairsCapture)
#print(somaticPairs)

BAMS_caller_hc	= ["SUBJECT/{subject}/{sample}/{reference_name}.{aligner}/haplotypecaller/{sample}.haplotypecaller.raw.vcf".format(subject=SAMPLE_TO_SUBJECT[s], sample=s, reference_name=config['reference_name'],aligner=config['aligner']) for s in config['samples'].keys()]
BAMS_caller_ps  = ["SUBJECT/{subject}/{sample}/{reference_name}.{aligner}/platypus/{sample}.platypus.raw.vcf".format(subject=SAMPLE_TO_SUBJECT[s], sample=s, reference_name=config['reference_name'],aligner=config['aligner']) for s in config['samples'].keys()]
BAMS_caller_fb  = ["SUBJECT/{subject}/{sample}/{reference_name}.{aligner}/freebayes/{sample}.freebayes.raw.vcf".format(subject=SAMPLE_TO_SUBJECT[s], sample=s, reference_name=config['reference_name'],aligner=config['aligner']) for s in config['samples'].keys()]

if len(config['sample_references']) > 0:
	BAMS_caller_sa_snv  = ["SUBJECT/{subject}/{sample}/{reference_name}.{aligner}/strelka/{sample}.strelka.snvs.raw.vcf".format(subject=SAMPLE_TO_SUBJECT[s], sample=s, reference_name=config['reference_name'],aligner=config['aligner']) for s in config['sample_references'].keys()]
	BAMS_caller_sa_indel  = ["SUBJECT/{subject}/{sample}/{reference_name}.{aligner}/strelka/{sample}.strelka.indels.raw.vcf".format(subject=SAMPLE_TO_SUBJECT[s], sample=s, reference_name=config['reference_name'],aligner=config['aligner']) for s in config['sample_references'].keys()]
	BAMS_caller_mt  = ["SUBJECT/{subject}/{sample}/{reference_name}.{aligner}/mutect/{sample}.mutect.raw.vcf".format(subject=SAMPLE_TO_SUBJECT[s], sample=s, reference_name=config['reference_name'],aligner=config['aligner']) for s in config['sample_references'].keys()]
else:
	BAMS_caller_mt=[]
	BAMS_caller_sa_indel=[]
	BAMS_caller_sa_snv=[]

All_caller_raw_vcf = BAMS_caller_hc + BAMS_caller_ps + BAMS_caller_fb + BAMS_caller_sa_snv + BAMS_caller_sa_indel + BAMS_caller_mt

#snpEff Annotation
ALL_snpEff_vcf1  = [] ; ALL_snpEff_vcf2  = [] ; ALL_SUBJECT_VCFS = {}
reference_name=config['reference_name'] ; aligner=config['aligner']

for sample in config['samples'].keys():
	subject=SAMPLE_TO_SUBJECT[sample]
	
	if subject not in ALL_SUBJECT_VCFS:
		ALL_SUBJECT_VCFS[subject]=[]
                ALL_SUBJECT_VCFS[subject].extend([("SUBJECT/"+subject+"/"+sample+"/"+reference_name+"."+aligner+"/haplotypecaller/"+sample+".haplotypecaller.snpEff.txt"),
                                                ("SUBJECT/"+subject+"/"+sample+"/"+reference_name+"."+aligner+"/platypus/"+sample+".platypus.snpEff.txt"),
                                                ("SUBJECT/"+subject+"/"+sample+"/"+reference_name+"."+aligner+"/freebayes/"+sample+".freebayes.snpEff.txt") ])
		ALL_snpEff_vcf1.extend(ALL_SUBJECT_VCFS[subject])	
 	
	else:
		ALL_SUBJECT_VCFS[subject].extend([("SUBJECT/"+subject+"/"+sample+"/"+reference_name+"."+aligner+"/haplotypecaller/"+sample+".haplotypecaller.snpEff.txt"),
			       			("SUBJECT/"+subject+"/"+sample+"/"+reference_name+"."+aligner+"/platypus/"+sample+".platypus.snpEff.txt"),
			       			("SUBJECT/"+subject+"/"+sample+"/"+reference_name+"."+aligner+"/freebayes/"+sample+".freebayes.snpEff.txt") ])
		ALL_snpEff_vcf1.extend(ALL_SUBJECT_VCFS[subject])	
	

if len(config['sample_references']) > 0:
	for sample in config['sample_references'].keys():
		subject=SAMPLE_TO_SUBJECT[sample]
		
	        if subject in ALL_SUBJECT_VCFS:
        		ALL_SUBJECT_VCFS[subject].extend([ ("SUBJECT/"+subject+"/"+sample+"/"+reference_name+"."+aligner+"/strelka/"+sample+".strelka.snvs.snpEff.txt"),
					 		("SUBJECT/"+subject+"/"+sample+"/"+reference_name+"."+aligner+"/strelka/"+sample+".strelka.indels.snpEff.txt"),
					 		("SUBJECT/"+subject+"/"+sample+"/"+reference_name+"."+aligner+"/mutect/"+sample+".mutect.snpEff.txt")])
			ALL_snpEff_vcf2.extend(ALL_SUBJECT_VCFS[subject])	
		else:
			print("Seems like there is no Germline caller for "+subject)	



ALL_snpEff_vcf = ALL_snpEff_vcf1 + ALL_snpEff_vcf2
##print(ALL_SUBJECT_VCFS)
#print(ALL_snpEff_vcf)

#Polyphen2 SIFT In-house Annotation
Annot_Annovar	= [] ; Annot_SIFT = [] ; Annot_PPH2 = []
FormatInput_out = ["SUBJECT/{subject}/Annotation/AnnotationInput.anno".format(subject=s) for s in config['subjects'].keys()] + ["SUBJECT/{subject}/Annotation/AnnotationInput.pph".format(subject=s) for s in config['subjects'].keys()] + ["SUBJECT/{subject}/Annotation/AnnotationInput.sift".format(subject=s) for s in config['subjects'].keys()]

#print(FormatInput_out)

Annot_Annovar =["SUBJECT/{subject}/Annotation/AnnotationInput.docm".format(subject=s) for s in config['subjects'].keys()] 
Annot_SIFT = ["SUBJECT/{subject}/Annotation/AnnotationInput.sift".format(subject=s) for s in config['subjects'].keys()] 
#Annot_PPH2 = ["SUBJECT/{subject}/Annotation/AnnotationInput.pph".format(subject=s) for s in config['subjects'].keys()] 
Annot_ALL = Annot_Annovar + Annot_SIFT + Annot_PPH2
#print(Annot_SIFT)

CombineAnnotation = [w.replace('docm','annotations.final.txt') for w in Annot_ALL] 

Attach_ASP_Annotation = [w.replace('snpEff', 'annotated') for w in ALL_snpEff_vcf]
#print(Attach_ASP_Annotation)

#test_input = "batch_out.txt"
rule final:
	input:
		All_QC,
		#ALL_snpEff_vcf,
		#FormatInput_out,
		#Annot_Annovar,
		#CombineAnnotation,
		Annot_SIFT,
		Attach_ASP_Annotation
		#Annot_ALL
		#BAMS
		#test_input
